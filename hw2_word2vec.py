# -*- coding: utf-8 -*-
"""hw2_word2vec.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1p1FxTUeP-PeCURG8EilT16SWgWbYuS-Z
"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# %pip install transformers datasets

"""# Word2Vec Model

Both the model implementation and the classification task will be included in this singular notebook to simplify the loading process of the checkpoints.
"""

import numpy as np
import matplotlib.pyplot as plt
import torch
import torch.nn.functional as F
import torch.nn as nn
import math
from torch.utils.data import DataLoader
from tabulate import tabulate
from datasets import load_dataset
from torch.utils.data import Dataset

from tqdm.notebook import tqdm
from transformers import BertTokenizer


# Move the model to the appropriate device (GPU if available)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

"""# Data loading


Let's start by loading the dataset and printing it to see what it looks like.
"""

dataset = load_dataset("scikit-learn/imdb", split="train")
print(dataset)

"""# Pre-processing / Tokenization

This is a very important step. It maybe boring but very important. In this session we will be lazy, but in real life, the time spent on inspecting and cleaning data is never wasted. It is true for text, but also for everything.



In PyTorch, everything is tensor. Words are replaced by indices. A sentence, is therefore a sequence of indices (long integers). In the first HW, you constructed a `WhiteSpaceTokenizer`. Here we will use an already built tokenizer. It is more appropriate to transformers. It relies on sub-word units, and converts everything in lower case. This is not always the best choice, but here it will be sufficient. To quote the documentation, this tokenizer allows you to:
- Tokenize (splitting strings in sub-word token strings), convert tokens strings to ids and back, and encoding/decoding (i.e., tokenizing and converting to integers).
- Add new tokens to the vocabulary in a way that is independent of the underlying structure (BPE, SentencePiece…).
- Manage special tokens (like mask, beginning-of-sentence, etc.): adding them, assigning them to attributes in the tokenizer for easy access and making sure they are not split during tokenization.

Here we are going to use the tokenizer from the well known Bert model, that we can directly download.
"""

tokenizer = BertTokenizer.from_pretrained("bert-base-uncased", do_lower_case=True)

def preprocessing_fn(x, tokenizer):
    x["review_ids"] = tokenizer(
        x["review"],
        add_special_tokens=False,
        truncation=True,
        max_length=256,
        padding=False,
        return_attention_mask=False,
    )["input_ids"]
    x["label"] = 0 if x["sentiment"] == "negative" else 1
    return x

"""After reading the documentation about HuggingFace dataset, we can now do the following:
- Shuffle the dataset
- For computational reasons, use only a total of **5000 samples**.
- Tokenize the dataset with the `preprocessing_fn`. (*Hint: use the `Dataset.map` method from HuggingFace*).
- Keep only columns `review_ids` and `label`.
- Make a train/validation split, (**80% / 20%**). Call these dataset `train_set` and `valid_set`.

"""

n_samples = 5000  # the number of training example
seed = 42 # random seed for our model so we can reproduce our results

torch.manual_seed(seed)
torch.cuda.manual_seed(seed)

# We first shuffle the data !
shuffled_dataset = dataset.shuffle(seed=seed)

# Select 5000 samples
small_dataset = shuffled_dataset.select(range(n_samples))

# Tokenize the dataset
tok_dataset = small_dataset.map(preprocessing_fn,
                                fn_kwargs={'tokenizer': tokenizer})

# Remove useless columns
tok_dataset = tok_dataset.select_columns(['review_ids', 'label'])

# Split the train and validation
tok_dataset = tok_dataset.train_test_split(test_size=0.2, seed=seed)

document_train_set = tok_dataset['train']
document_valid_set = tok_dataset['test']

print(document_train_set)

"""# Implementation

This section will include the steps and workflow followed for the creation of my own Word2Vec model. Each question corresponding to the instructions.pdf will be clearly labeled and explained below.

## Data preprocessing

1. Can be found in the sections above, I applied the same preprocessing to get a dataset (with the same tokenizer)
with a `train` and a `validation` split, with two columns `review_ids` (list of int) and `label` (int).

2. Below, is the function `extract_words_contexts`. To handle the borders and ensure that every context has the same size, I am using a padding token that allows words at the beginning and end of our data to still be extracted along with their contexts. This is represented by `padding_token` in my function below. By padding at both ends, I ensure that even the first and last words of the document can have a full context window. I have chosen a padding token ID of `0` because it does not clash with any word IDs in my dataset, and has a set label of ['PAD'] when printing the words and contexts.
"""

def extract_words_contexts(ids, R, padding_token=0):
    words = []
    contexts = []

    padded_ids = [padding_token] * R + ids + [padding_token] * R

    for i in range(R, len(padded_ids) - R):
        word = padded_ids[i]
        context = padded_ids[i-R:i] + padded_ids[i+1:i+R+1]

        words.append(word)
        contexts.append(context)

    return words, contexts

"""3. Below is the function `flatten_dataset_to_list` that applies the function
`extract_words_contexts` on the whole dataset.
"""

def flatten_dataset_to_list(dataset, R):
    all_words = []
    all_contexts = []

    for document in dataset:
        words, contexts = extract_words_contexts(document['review_ids'], R)

        all_words.extend(words)
        all_contexts.extend(contexts)

    return all_words, all_contexts

"""4. I will now apply the function to my initial `document_train_set` and `document_valid_set` to get the corresponding flattened lists. I will also print some example outputs to get a look at what the `extract_words_contexts` function is doing.

"""

R = 6
K = 10

flat_train_words, flat_train_contexts = flatten_dataset_to_list(document_train_set, R)
flat_valid_words, flat_valid_contexts = flatten_dataset_to_list(document_valid_set, R)


print("Example outputs:")
for i in range(5):  # Adjust the range to see more or fewer examples
    print(f"Central Word ID: {flat_train_words[i]}")
    print(f"Context IDs: {flat_train_contexts[i]}")
    print("-" * 20)

"""5. I will now embed these lists in two valid PyTorch `Dataset`, and call them `train_set` and `valid_set`."""

class TextDataset(Dataset):
    def __init__(self, words, contexts):
        self.words = words
        self.contexts = contexts

    def __len__(self):
        return len(self.words)

    def __getitem__(self, idx):
        return {
            'word_id': self.words[idx],
            'context_ids': self.contexts[idx]
        }

train_set = TextDataset(flat_train_words, flat_train_contexts)
valid_set = TextDataset(flat_valid_words, flat_valid_contexts)

"""6. I will now make the `collate_fn` function that adds the negative context to the batch. It will be parameterized by the scaling factor K, and the output of `collate_fn` will be the Python dictionary that can be seen in the code below. It contains the necessary information on word IDs, positive context IDs, and negative context IDs. For the negative context, I will randomly sample from the whole vocabulary set. This is done with the `random` package to sample from `tokenizer.vocab_size`. Since we are using the `BERT` tokenizer which already has its own vocabulary set, we can randomly sample directly from that vocabulary."""

import random
random.seed(seed)

def collate_fn(batch, R, K):
    word_ids = [item['word_id'] for item in batch]
    positive_context_ids = [item['context_ids'] for item in batch]
    negative_context_ids = [random.sample(range(tokenizer.vocab_size), 2*K*R) for _ in batch]

    return {
        'word_id': torch.tensor(word_ids).cuda(),
        'positive_context_ids': torch.tensor(positive_context_ids).cuda(),
        'negative_context_ids': torch.tensor(negative_context_ids).cuda()
    }

"""7. Now I will wrap everything in a `DataLoader` to simplify access to training and validation data that will be used to actually train the final model. I chose a batch size (defined by `B`) of 16 to start, as recommended by the authors of the BERT model."""

B = 32 # Batch size

train_dataloader = DataLoader(
    train_set, batch_size=B, collate_fn=lambda x: collate_fn(x, R, K)
)
valid_dataloader = DataLoader(
    valid_set, batch_size=B, collate_fn=lambda x: collate_fn(x, R, K)
)
n_valid = len(valid_set)
n_train = len(train_set)

"""8. I will now make 2 or 3 three iterations in the `DataLoader` and print R, K and the
shapes of all the tensors in the batches.
"""

for _ in range(3):
    for batch in train_dataloader:
        print(f"R: {R}, K: {K}")
        print("word_id shape:", batch['word_id'].shape)
        print("positive_context_ids shape:", batch['positive_context_ids'].shape)
        print("negative_context_ids shape:", batch['negative_context_ids'].shape)
        break  # To only print the first batch

"""## Model

I will now build my `Word2Vec` model, and implement it. It will be defined as a class that inherits from the `torch.nn.Module`. The model will be parametrized by the vocabulary size, which we discussed earlier, and the embeddings dimension. I am using the module `torch.nn.Embedding`. I will start with a recommended amount of 100 embeddings. This can be changed later on to help tune the model and increase accuracy.
"""

class Word2Vec(nn.Module):
    def __init__(self, vocab_size, embedding_dim):
        super(Word2Vec, self).__init__()
        # Embedding table for target words
        self.target_embeddings = nn.Embedding(vocab_size, embedding_dim)
        # Embedding table for context words
        self.context_embeddings = nn.Embedding(vocab_size, embedding_dim)

    def forward(self, target_words, context_words, labels):
        # Get embeddings for target words
        target_embeds = self.target_embeddings(target_words)
        # Get embeddings for context words
        context_embeds = self.context_embeddings(context_words)
        # Compute the dot product
        scores = torch.bmm(context_embeds, target_embeds.unsqueeze(2)).squeeze(2)
        # Apply sigmoid function to get probabilities
        probs = torch.sigmoid(scores)

        return probs


vocab_size = len(tokenizer.vocab)  # BERT tokenizer vocabulary size
d = 100 # number of embedding dimensions

model_word2vec = Word2Vec(vocab_size, d)

"""I will define some hyperparameters, as well as define the optimizer. I am using the popular `Adam` optimizer. I will then initiate the device so that I can train my model on a GPU if possible to accelerate the process.

I have chosen the below hyperparameters based on the recommendations of the authors of the BERT paper once again. This can also be changed later on to help tune the model and increase accuracy.
"""

# Hyperparameters
learning_rate = 5e-5
epsilon = 1e-08
E = 30  # Number of epochs

# Define the optimizer
optimizer = torch.optim.AdamW(model_word2vec.parameters(), lr=learning_rate, eps=epsilon)
optimizer_1 = torch.optim.Adam(model_word2vec.parameters(), lr=learning_rate)

model_word2vec.to(device)

"""I can now train my model using the below `train_word2vec` function, and validate the accuracy on the test set using the `validate_word2vec` function. The training will be parametrized by the batch size B, and the number of epochs E, define previously."""

def train_model(model, train_loader, valid_loader, E, optimizer, device):
    list_val_acc = []
    list_train_acc = []
    list_train_loss = []
    list_val_loss = []
    criterion = nn.BCELoss()

    for e in range(E):
        model.train()
        total_loss = 0
        correct_predictions = 0
        total_predictions = 0

        for batch in tqdm(train_loader):
            # Get data from the batch
            word_ids = batch['word_id'].to(device)
            pos_context_ids = batch['positive_context_ids'].to(device)
            neg_context_ids = batch['negative_context_ids'].to(device)

            # Combine positive and negative context ids
            context_ids = torch.cat((pos_context_ids, neg_context_ids), dim=1)

            # Labels: 1 for positive context, 0 for negative context
            labels = torch.cat((torch.ones(pos_context_ids.size(0), pos_context_ids.size(1)),
                                torch.zeros(neg_context_ids.size(0), neg_context_ids.size(1))), dim=1).to(device)

            # Forward pass
            optimizer.zero_grad()
            preds = model(word_ids, context_ids, labels)
            loss = criterion(preds, labels)

            # Backward pass and optimization
            loss.backward()
            optimizer.step()

            # Calculate the binary predictions
            with torch.no_grad():
                predictions = (preds > 0.5).float()
                correct_predictions += (predictions == labels).sum().item()
                total_predictions += labels.numel()

            total_loss += loss.item()

        # Calculate average loss and accuracy
        avg_loss = total_loss / len(train_loader)
        accuracy = 100 * (correct_predictions / total_predictions)

        list_train_loss.append(avg_loss)
        list_train_acc.append(accuracy)

        # Validate the model after each epoch
        val_loss, val_acc = validate_model(model, valid_dataloader, device)
        list_val_loss.append(val_loss)
        list_val_acc.append(val_acc)

        print(
            f"Epoch {e+1}\n\t - Train loss: {list_train_loss[-1]:.4f}",
            f"Train acc: {list_train_acc[-1]:.4f}",
            f"Val loss: {list_val_loss[-1]:.4f}",
            f"Val acc: {list_val_acc[-1]:.4f}"
        )
    return list_train_loss, list_train_acc, list_val_loss, list_val_acc


def validate_model(model, valid_loader, device):
    model.eval()
    total_loss = 0
    correct_predictions = 0
    total_predictions = 0
    criterion = nn.BCELoss()

    with torch.no_grad():
        for batch in tqdm(valid_loader):
            word_ids = batch['word_id'].to(device)
            pos_context_ids = batch['positive_context_ids'].to(device)
            neg_context_ids = batch['negative_context_ids'].to(device)
            context_ids = torch.cat((pos_context_ids, neg_context_ids), dim=1)
            labels = torch.cat((torch.ones(pos_context_ids.size(0), pos_context_ids.size(1)),
                                torch.zeros(neg_context_ids.size(0), neg_context_ids.size(1))), dim=1).to(device)

            preds = model(word_ids, context_ids, labels)
            loss = criterion(preds, labels)

            # Calculate the binary predictions
            predictions = (preds > 0.5).float()
            correct_predictions += (predictions == labels).sum().item()
            total_predictions += labels.numel()

            total_loss += loss.item()

        # Calculate average loss and accuracy
        avg_loss = total_loss / len(valid_loader)
        accuracy = 100 * (correct_predictions / total_predictions)
        return avg_loss, accuracy

"""Let's train the model ! The output of my functions containing the accuracy and loss for each epoch can be seen below after running the code."""

list_train_loss, list_train_acc, list_val_loss, list_val_acc = train_model(
    model_word2vec, train_dataloader, valid_dataloader, E, optimizer, device)

"""For the purpose of visualizing our loss and accuracy results over the epochs, below is code to create graphical representations of these changes."""

# Plot training & validation loss values
plt.figure(figsize=(12, 2))
plt.subplot(1, 2, 1)
plt.plot(list_train_loss, label='Train')
plt.plot(list_val_loss, label='Validation')
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(loc='upper right')

# Plot training & validation accuracy values
plt.subplot(1, 2, 2)
plt.plot(list_train_acc, label='Train')
plt.plot(list_val_acc, label='Validation')
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(loc='lower right')

plt.show()

"""I can observe that over the course of the epochs, both my training and validation losses decrease as expected. At the same time, my training and validation accuracies are increasing which shows improvement in the model training. This is consistent with the results I was expecting.

I will now write a function `save_model` that saves my Word2Vec model’s embeddings in a file so that they can be loaded later for the classification task.
"""

def save_model(model, d, R, K, B, E):
    file_name = f"model_dim-{d}_radius-{R}_ratio-{K}-batch-{B}-epoch-{E}.ckpt"
    embeddings = model.target_embeddings.weight.data
    checkpoint = {
        'embedding_words.weight': embeddings
    }
    torch.save(checkpoint, file_name)

save_model(model_word2vec, d, R, K, B, E)

"""---
---

# Classification Task

In this section I will experiment with the classification task of the lab, augmented with my Word2Vec model. This task utilizes a Convolutional model that I have defined as `Conv1dClassifier`, which uses the `nn.Conv1d` module of torch. I will first train this model with an initialization using the embeddings saved from my `Word2Vec` model. After training this model, I will compare it to a simple model, trained with some randomly chosen intialization parameters. Comparing the results of the two models will give some insight into how performant the embeddings from my first model are.

First, I will go through the process of quickly pre-processing the data again to prepare it for my convolutional classifier model.
"""

dataset = load_dataset("scikit-learn/imdb", split="train")
print(dataset)

def preprocessing_fn(x, tokenizer):
    x["review_ids"] = tokenizer(
        x["review"],
        add_special_tokens=False,
        truncation=True,
        max_length=256,
        padding=False,
        return_attention_mask=False,
    )["input_ids"]
    x["label"] = 0 if x["sentiment"] == "negative" else 1
    return x

n_samples = 5000  # the number of training example
# We first shuffle the data !
dataset = dataset.shuffle(seed=seed)
# Select 5000 samples
dataset = dataset.select(range(n_samples))
# Tokenize the dataset
dataset = dataset.map(lambda x: preprocessing_fn(x, tokenizer), batched=False)
# Remove useless columns
dataset = dataset.remove_columns(['review','sentiment'])
# Split the train and validation
dataset = dataset.train_test_split(train_size=.8, seed=seed)
train_set = dataset['train']
valid_set = dataset['test']

class DataCollator:
    def __init__(self, tokenizer):
        self.tokenizer = tokenizer

    def __call__(self, batch):
        # `batch` is a list of dictionary with keys "review_ids" and "label".
        features = [{"input_ids": x["review_ids"]} for x in batch]
        features = self.tokenizer.pad(
            features, padding="max_length", max_length=256, return_tensors="pt"
        )
        labels = torch.tensor([x["label"] for x in batch])  # No need for [:, None]
        return {"review_ids": features["input_ids"], "label": labels}

data_collator = DataCollator(tokenizer)
batch_size = 64
train_dataloader_conv = DataLoader(
    train_set, batch_size=batch_size, collate_fn=data_collator
)
valid_dataloader_conv = DataLoader(
    valid_set, batch_size=batch_size, collate_fn=data_collator
)
n_valid = len(valid_set)
n_train = len(train_set)

"""Now I will load the embeddings of my `Word2Vec` model using the `load_model` function defined below. This will access the embeddings weights saved in a checkpoint file and return them as an `nn.Embedding` layer that I can use in the convolutional classifier model."""

def load_model(word2vec_path, freeze=False):
    word2vec_checkpoint = torch.load(word2vec_path)
    pretrained_embeddings  = word2vec_checkpoint['embedding_words.weight']
    num_embeddings, embedding_dim = pretrained_embeddings.size()
    embedding_layer = nn.Embedding.from_pretrained(pretrained_embeddings, freeze=freeze)
    return embedding_layer, embedding_dim

# Load Word2Vec model
checkpoint_path = rf'/content/model_dim-{d}_radius-{R}_ratio-{K}-batch-{B}-epoch-{E}.ckpt'
word2vec_embeddings, embedding_dim = load_model(checkpoint_path)

"""Below, I am creating the model class for my first Convolutional classifier model which will be initialized using the loaded embeddings from my `Word2Vec` model. I will call this model `Conv1dClassifier_with_word2vec_embeddings` in order to properly identify it. For `self.embedding`, I am directly loading the embeddings instead of defining a new embedding layer."""

class Conv1dClassifier_with_word2vec_embeddings(nn.Module):
    """A text classifier:
    - input = minibatch
    - output = probability associated to a binary classification task
    - vocab_size: the number of words in the vocabulary we want to embed
    - embedding_dim: size of the word vectors
    """

    def __init__(self, vocab_size, embedding_dim, word2vec_embeddings, feature_size=100, kernel_size=3):
        super().__init__()
        self.embedding_dim = embedding_dim
        self.feature_size = feature_size

        self.embedding = word2vec_embeddings

        self.conv = nn.Conv1d(in_channels=self.embedding_dim, out_channels=self.feature_size, kernel_size=kernel_size, padding=1)
        self.relu = nn.ReLU()
        self.pooling_layer = nn.AdaptiveMaxPool1d(output_size=2)
        self.flatten_layer = nn.Flatten()
        self.linear_layer = nn.LazyLinear(out_features=2)
        self.softmax_layer = nn.Softmax(dim=1)

    def forward(self, input_ids):
        embedding_output = self.embedding(input_ids.to(device))
        conv_output = self.conv(embedding_output.permute(0, 2, 1))
        pooling_output = self.pooling_layer(self.relu(conv_output))
        flattened_output = self.flatten_layer(pooling_output)
        linear_output = self.linear_layer(flattened_output)
        return linear_output

"""Now that I have defined my model, I can train it to obtain the training loss, training accuracy, validation loss, and validation accuracy of the classification model using the `Word2Vec` model embeddings."""

def train_with_embeddings(train_dataloader_conv, valid_dataloader_conv,
                          word2vec_embeddings, embedding_dim, num_epochs):
  ## Define the training loss
  loss_function = nn.CrossEntropyLoss()
  ## The optimizer
  model_conv_w_emb = Conv1dClassifier_with_word2vec_embeddings(
      vocab_size=tokenizer.vocab_size, embedding_dim=embedding_dim,
      word2vec_embeddings=word2vec_embeddings
  )
  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
  model_conv_w_emb.to(device)

  optimizer = torch.optim.Adam(params=model_conv_w_emb.parameters(), lr=1e-2)

  list_val_acc_conv_emb = []
  list_train_acc_conv_emb = []
  list_train_loss_conv_emb = []
  list_val_loss_conv_emb = []

  for e in range(num_epochs):
      # Training
      model_conv_w_emb.train()
      train_loss_per_epoch = []
      train_correct = 0
      train_total = 0
      for batch in tqdm(train_dataloader_conv):
          inputs, targets = batch['review_ids'].to(device), batch['label'].to(device)
          optimizer.zero_grad()
          outputs = model_conv_w_emb(inputs)
          loss = loss_function(outputs, targets)
          loss.backward()
          optimizer.step()

          train_loss_per_epoch.append(loss.item())
          _, predicted = torch.max(outputs, 1)
          train_total += targets.size(0)
          train_correct += (predicted == targets).sum().item()

      train_accuracy = 100 * train_correct / train_total

      # Validation
      model_conv_w_emb.eval()
      valid_loss_per_epoch = []
      valid_correct = 0
      valid_total = 0
      with torch.no_grad():
          for batch in tqdm(valid_dataloader_conv):
              inputs, targets = batch['review_ids'].to(device), batch['label'].to(device)
              outputs = model_conv_w_emb(inputs)
              loss = loss_function(outputs, targets)
              valid_loss_per_epoch.append(loss.item())
              _, predicted = torch.max(outputs, 1)
              valid_total += targets.size(0)
              valid_correct += (predicted == targets).sum().item()

      valid_accuracy = 100 * valid_correct / valid_total

      print('-' * 100)
      print(f'Epoch: {e+1}')
      print(f'Train Loss: {np.mean(train_loss_per_epoch):.4f} | Train Accuracy: {train_accuracy:.2f}%')
      print(f'Valid Loss: {np.mean(valid_loss_per_epoch):.4f} | Valid Accuracy: {valid_accuracy:.2f}%')

      list_val_acc_conv_emb.append(valid_accuracy)
      list_train_acc_conv_emb.append(train_accuracy)
      list_train_loss_conv_emb.append(np.mean(train_loss_per_epoch))
      list_val_loss_conv_emb.append(np.mean(valid_loss_per_epoch))

  return list_val_acc_conv_emb, list_train_acc_conv_emb, list_train_loss_conv_emb, list_val_loss_conv_emb

list_val_acc_conv_emb, list_train_acc_conv_emb, list_train_loss_conv_emb, list_val_loss_conv_emb = train_with_embeddings(
    train_dataloader_conv, valid_dataloader_conv, word2vec_embeddings, embedding_dim, num_epochs=3)

"""I now have the loss and accuracy results for both the training and validation for my convolutional model using the `Word2Vec` model embeddings. I will use these later on to produce graphical representations in order to compare this model to the convolutional model without the embeddings initialization.

Now, I will create the second convolutional classifier model without the `Word2Vec` model initialization in order to compare their results. This model will be named `Conv1dClassifier` and will use an embedding layer `nn.Embedding` which will be parameterized by the randomly chosen `vocab_size` and `embedding_dim` parameters. This can be seen below when defining the embedding layer `self.embedding` in the model. Once trained, this model should produce different results than the previous convolutional model.
"""

class Conv1dClassifier(nn.Module):
    """A text classifier:
    - input = minibatch
    - output = probability associated to a binary classification task
    - vocab_size: the number of words in the vocabulary we want to embed
    - embedding_dim: size of the word vectors
    """

    def __init__(self, vocab_size, embedding_dim, feature_size=100, kernel_size=3):
        super().__init__()
        self.embedding_dim = embedding_dim
        self.feature_size = feature_size

        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=self.embedding_dim)

        self.conv = nn.Conv1d(in_channels=self.embedding_dim, out_channels=self.feature_size, kernel_size=kernel_size, padding=1)
        self.relu = nn.ReLU()
        self.pooling_layer = nn.AdaptiveMaxPool1d(output_size=2)
        self.flatten_layer = nn.Flatten()
        self.linear_layer = nn.LazyLinear(out_features=2)
        self.softmax_layer = nn.Softmax(dim=1)

    def forward(self, input_ids):
        embedding_output = self.embedding(input_ids.to(device))
        conv_output = self.conv(embedding_output.mT)
        pooling_output = self.pooling_layer(self.relu(conv_output))
        flattened_output = self.flatten_layer(pooling_output)
        linear_output = self.linear_layer(flattened_output)
        return linear_output

"""Just like with the first convolutional model, now that I have defined my new classification model, I can train it to obtain the training loss, training accuracy, validation loss, and validation accuracy."""

## Define the training loss
loss_function = nn.CrossEntropyLoss()
## The optimizer
model_conv = Conv1dClassifier(
    vocab_size=tokenizer.vocab_size, embedding_dim=100
)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model_conv.to(device)

optimizer = torch.optim.Adam(params=model_conv.parameters(), lr=1e-2)

num_epochs = 3

list_val_acc_conv = []
list_train_acc_conv = []
list_train_loss_conv = []
list_val_loss_conv = []

for e in range(num_epochs):
    # Training
    model_conv.train()
    train_loss_per_epoch = []
    train_correct = 0
    train_total = 0
    for batch in tqdm(train_dataloader_conv):
        inputs, targets = batch['review_ids'].to(device), batch['label'].to(device)
        optimizer.zero_grad()
        outputs = model_conv(inputs)
        loss = loss_function(outputs, targets)
        loss.backward()
        optimizer.step()

        train_loss_per_epoch.append(loss.item())
        _, predicted = torch.max(outputs, 1)
        train_total += targets.size(0)
        train_correct += (predicted == targets).sum().item()

    train_accuracy = 100 * train_correct / train_total

    # Validation
    model_conv.eval()
    valid_loss_per_epoch = []
    valid_correct = 0
    valid_total = 0
    with torch.no_grad():
        for batch in tqdm(valid_dataloader_conv):
            inputs, targets = batch['review_ids'].to(device), batch['label'].to(device)
            outputs = model_conv(inputs)
            loss = loss_function(outputs, targets)
            valid_loss_per_epoch.append(loss.item())
            _, predicted = torch.max(outputs, 1)
            valid_total += targets.size(0)
            valid_correct += (predicted == targets).sum().item()

    valid_accuracy = 100 * valid_correct / valid_total

    print('-' * 100)
    print(f'Epoch: {e+1}')
    print(f'Train Loss: {np.mean(train_loss_per_epoch):.4f} | Train Accuracy: {train_accuracy:.2f}%')
    print(f'Valid Loss: {np.mean(valid_loss_per_epoch):.4f} | Valid Accuracy: {valid_accuracy:.2f}%')

    list_val_acc_conv.append(valid_accuracy)
    list_train_acc_conv.append(train_accuracy)
    list_train_loss_conv.append(np.mean(train_loss_per_epoch))
    list_val_loss_conv.append(np.mean(valid_loss_per_epoch))

"""I now have the loss and accuracy results for both the training and validation for my convolutional model without the embeddings initialization. I will now use these along with the previous model results to produce a graphical representation which will allow me to compare the two models.

### Comparing Results

Below is the code used to make the graphical comparison of the metric results of both models.
"""

def plot_model_comparisons(model1_data, model2_data, epochs):
    fig, axes = plt.subplots(2, 2, figsize=(14, 5))
    fig.suptitle('Model Training and Validation Metrics Comparison')

    # Unpack data
    val_loss1, val_acc1, train_loss1, train_acc1 = model1_data
    val_loss2, val_acc2, train_loss2, train_acc2 = model2_data

    # Epochs array
    epoch_range = list(range(1, epochs + 1))

    # Validation Loss
    axes[0, 0].plot(epoch_range, val_loss1, 'b-', label='Convolution Model with Word2Vec embeddings')
    axes[0, 0].plot(epoch_range, val_loss2, 'r-', label='Convolution Model without')
    axes[0, 0].set_title('Validation Loss')
    axes[0, 0].set_xlabel('Epochs')
    axes[0, 0].set_ylabel('Loss')
    axes[0, 0].legend()

    # Validation Accuracy
    axes[0, 1].plot(epoch_range, val_acc1, 'b-', label='Convolution Model with Word2Vec embeddings')
    axes[0, 1].plot(epoch_range, val_acc2, 'r-', label='Convolution Model without')
    axes[0, 1].set_title('Validation Accuracy')
    axes[0, 1].set_xlabel('Epochs')
    axes[0, 1].set_ylabel('Accuracy')
    axes[0, 1].legend()

    # Training Loss
    axes[1, 0].plot(epoch_range, train_loss1, 'b-', label='Convolution Model with Word2Vec embeddings')
    axes[1, 0].plot(epoch_range, train_loss2, 'r-', label='Convolution Model without')
    axes[1, 0].set_title('Training Loss')
    axes[1, 0].set_xlabel('Epochs')
    axes[1, 0].set_ylabel('Loss')
    axes[1, 0].legend()

    # Training Accuracy
    axes[1, 1].plot(epoch_range, train_acc1, 'b-', label='Convolution Model with Word2Vec embeddings')
    axes[1, 1].plot(epoch_range, train_acc2, 'r-', label='Convolution Model without')
    axes[1, 1].set_title('Training Accuracy')
    axes[1, 1].set_xlabel('Epochs')
    axes[1, 1].set_ylabel('Accuracy')
    axes[1, 1].legend()

    # Layout adjustment
    plt.tight_layout(rect=[0, 0.03, 1, 0.95])

    # Show plot
    plt.show()

# Example data
model1_data = (list_val_loss_conv_emb, list_val_acc_conv_emb, list_train_loss_conv_emb, list_train_acc_conv_emb)
model2_data = (list_val_loss_conv, list_val_acc_conv, list_train_loss_conv, list_train_acc_conv)

# Call function
plot_model_comparisons(model1_data, model2_data, num_epochs)

"""As can be observed from the above graphs, after training for 3 epochs, using the embeddings of Word2Vec as initialization for the convolutional model does not improve performance, and in fact becomes worse than a model with simple initialization. This is not expected, but shows that the Word2Vec embeddings are not appropriate for a classification model. Aside from the validation loss, the other metrics are behaving as expected, with loss decreasing and accuracy increasing over the epochs. After multiple different experiments with a consistent random seed value, I noticed no change in the performance trend of these models.

### Ablation Study

In my ablation study, I decided to test the influence of some parameters of the Word2Vec model on the classification task. For this, I set up different configurations for my Word2Vec model, and decided to test specifically different embedding dimensions and different batch sizes. For embeddding dimensions, I tested values of 50 and 100, and for batches, I decided to test values of 16 and 32, which is recommend for a smaller dataset such as the one I am using. Additionally, I added a testing of different epochs, but this will only be used to configure the Word2Vec model, and not the convolutional models.
"""

# Define different configurations for Word2Vec
configurations = [
    {'embedding_size': 50, 'batch': 16, 'radius': 4, 'ratio': 6},
    {'embedding_size': 50, 'batch': 32, 'radius': 4, 'ratio': 10},
    {'embedding_size': 100, 'batch': 32, 'radius': 6, 'ratio': 8},
    {'embedding_size': 100, 'batch': 64, 'radius': 6, 'ratio': 10},
    {'embedding_size': 100, 'batch': 16, 'radius': 8, 'ratio': 6},
    {'embedding_size': 100, 'batch': 32, 'radius': 4, 'ratio': 10},
    {'embedding_size': 200, 'batch': 32, 'radius': 6, 'ratio': 8},
    {'embedding_size': 200, 'batch': 64, 'radius': 8, 'ratio': 10}
]

results = []

for config in configurations:
    embs = config['embedding_size']
    epochs = 30
    batch_size = config['batch']
    R = config['radius']
    K = config['ratio']

    # Train Word2Vec with the current configuration
    flat_train_words, flat_train_contexts = flatten_dataset_to_list(document_train_set, R)
    flat_valid_words, flat_valid_contexts = flatten_dataset_to_list(document_valid_set, R)

    train_set = TextDataset(flat_train_words, flat_train_contexts)
    valid_set = TextDataset(flat_valid_words, flat_valid_contexts)

    train_dataloader = DataLoader(
        train_set, batch_size=batch_size, collate_fn=lambda x: collate_fn(x, R, K)
    )
    valid_dataloader = DataLoader(
        valid_set, batch_size=batch_size, collate_fn=lambda x: collate_fn(x, R, K)
    )

    model_word2vec = Word2Vec(vocab_size, embs)
    model_word2vec.to(device)
    train_model(model_word2vec, train_dataloader, valid_dataloader, epochs, optimizer, device)

    # Save the embeddings
    save_model(model_word2vec, embs, R, K, batch_size, epochs)

    # Load the embeddings into the Conv1dClassifier using load_model
    checkpoint_path = rf'/content/model_dim-{embs}_radius-{R}_ratio-{K}-batch-{batch_size}-epoch-{epochs}.ckpt'
    word2vec_embeddings, embedding_dim = load_model(checkpoint_path)

    # Initialize Conv1dClassifier model with embeddings
    model_conv = Conv1dClassifier_with_word2vec_embeddings(
      vocab_size=tokenizer.vocab_size, embedding_dim=embedding_dim,
      word2vec_embeddings=word2vec_embeddings
    )

    # Redefine dataloaders for Conv1dClassifier with new batch sizes
    train_set = dataset['train']
    valid_set = dataset['test']

    data_collator = DataCollator(tokenizer)
    train_dataloader_conv_ab = DataLoader(
        train_set, batch_size=batch_size, collate_fn=data_collator
    )
    valid_dataloader_conv_ab = DataLoader(
        valid_set, batch_size=batch_size, collate_fn=data_collator
    )

    # Train the Conv1dClassifier
    list_val_acc, list_train_acc, list_train_loss, list_val_loss = train_with_embeddings(
        train_dataloader_conv_ab, valid_dataloader_conv_ab, word2vec_embeddings, embedding_dim, num_epochs=3)

    # Evaluate the classifier and store metrics
    # results.append((config, min(list_train_loss), min(list_val_loss), max(list_train_acc), max(list_val_acc)))
    results.append((config, list_train_loss[-1], list_val_loss[-1], list_train_acc[-1], list_val_acc[-1]))

# Analyze results
for config, train_loss, val_loss, train_acc, val_acc in results:
    print(f"Configuration: {config}, Train Loss: {train_loss:.4f}, Valid Loss: {val_loss:.4f}, Train Accuracy: {train_acc:.2f}, Valid Accuracy: {val_acc:.2f}")

"""From these results, it can be observed that an embedding size of 100, batch size of 64, radius of 6, and ratio of 10 seems to be the best configuration of parameters. However, it can be concluded from this experiment that the batch size and ratio values seem to have the most influence on the classification task, as they are the two parameters that caused the most improvement when increased.

In the code below, I will create some bar plot representations of these results in order to show comparisons of the different values of each parameter and what effects they have on the final training and validation metrics.
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# Assuming 'results' is a list of tuples containing configurations and their corresponding
# train loss, validation loss, train accuracy, and validation accuracy.
# Convert the results into a structured DataFrame
df_results = pd.DataFrame([{
    **config,
    'Train Loss': train_loss,
    'Validation Loss': val_loss,
    'Train Accuracy': train_acc,
    'Validation Accuracy': val_acc
} for config, train_loss, val_loss, train_acc, val_acc in results])

# Define a function to create grouped bar charts for each parameter with annotations
def plot_grouped_bars(df, parameter, metrics):
    unique_values = df[parameter].unique()
    unique_values.sort()

    # Calculate metrics for each parameter setting
    metrics_values = {metric: [df[df[parameter] == value][metric].mean() for value in unique_values] for metric in metrics}

    # Set plot properties
    n = len(unique_values)
    ind = np.arange(n)
    width = 0.2  # width of the bars

    fig, ax = plt.subplots(figsize=(10, 6))

    # Create bars for each metric
    bars = []
    for i, metric in enumerate(metrics):
        bar = ax.bar(ind + i * width, metrics_values[metric], width, label=metric)
        bars.append(bar)
        # Add text annotation on top of each bar
        for rect in bar:
            height = rect.get_height()
            ax.annotate(f'{height:.2f}',
                        xy=(rect.get_x() + rect.get_width() / 2, height),
                        xytext=(0, 3),  # 3 points vertical offset
                        textcoords="offset points",
                        ha='center', va='bottom')

    # Add some text for labels, title, and custom x-axis tick labels, etc.
    ax.set_xlabel(parameter)
    ax.set_ylabel('Metrics')
    ax.set_title(f'Metrics by {parameter} and metric type')
    ax.set_xticks(ind + width / len(metrics) * (len(metrics) - 1) / 2)
    ax.set_xticklabels(unique_values)
    ax.legend()

    plt.show()

# You can now call plot_grouped_bars for both accuracy and loss metrics.

# For 'embedding_size'
plot_grouped_bars(df_results, 'embedding_size', ['Train Accuracy', 'Validation Accuracy'])
plot_grouped_bars(df_results, 'embedding_size', ['Train Loss', 'Validation Loss'])

# For 'batch_size' (assuming the parameter is 'batch_size' not 'batch')
plot_grouped_bars(df_results, 'batch', ['Train Accuracy', 'Validation Accuracy'])
plot_grouped_bars(df_results, 'batch', ['Train Loss', 'Validation Loss'])

# For 'radius'
plot_grouped_bars(df_results, 'radius', ['Train Accuracy', 'Validation Accuracy'])
plot_grouped_bars(df_results, 'radius', ['Train Loss', 'Validation Loss'])

# For 'ratio'
plot_grouped_bars(df_results, 'ratio', ['Train Accuracy', 'Validation Accuracy'])
plot_grouped_bars(df_results, 'ratio', ['Train Loss', 'Validation Loss'])

"""As can be observed from the bar plots, the conclusions drawn from the printed configurations above are confirmed. The metric results are indeed best influenced by an embedding dimension of 100, batch size of 64, radius of 6, and ratio of 10."""